{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tsfresh import extract_features\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import RFECV\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score,  f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_extract=pd.read_csv(\"..\\chapter4\\data_to_extraction.csv\").drop(columns=\"Unnamed: 0\")\n",
    "data_to_extract.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_extract.groupby(\"PACJENT_NR\").last()[\"BADANIE_NR\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data_to_extract.groupby(\"PACJENT_NR\").last()[\"ZGON\"].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_columns=['BETET', 'CO2TET', 'HCO3ACTE', 'HCO3STTE',\n",
    "       'O2SATTET', 'O2TET', 'IONH', 'BETET_kw', 'O2TET_kw',\n",
    "       'HCO3ACTE_kw', 'HCO3STTE_kw', 'O2SATTET_kw', 'IONH_kw', 'CO2TET_kw',\n",
    "       'BETET_pn', 'O2TET_pn', 'HCO3ACTE_pn', 'HCO3STTE_pn', 'O2SATTET_pn',\n",
    "       'IONH_pn', 'CO2TET_pn', 'euclidean_kw', 'euclidean_kw_skum']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(var_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = {\n",
    "    'minimum': None,\n",
    "    'maximum': None,\n",
    "    'mean': None,\n",
    "    'median': None,\n",
    "    'variance': None,\n",
    "    'number_peaks': [{'n': 2}, {'n': 4}],\n",
    "    'first_location_of_minimum': None,\n",
    "    'first_location_of_maximum': None,\n",
    "    'linear_trend': [{'attr': 'slope'}],\n",
    "    'agg_linear_trend': [\n",
    "        {'f_agg': 'mean', 'chunk_len': 3, 'attr': 'slope'},\n",
    "        {'f_agg': 'mean', 'chunk_len': 6, 'attr': 'slope'},\n",
    "        {'f_agg': 'max', 'chunk_len': 3, 'attr': 'slope'},\n",
    "        {'f_agg': 'max', 'chunk_len': 6, 'attr': 'slope'}\n",
    "    ]\n",
    "}\n",
    "\n",
    "extracted_features = pd.DataFrame()\n",
    "\n",
    "for col in var_columns:\n",
    "    features = extract_features(data_to_extract, column_id=\"PACJENT_NR\", column_sort=\"BADANIE_NR\", \n",
    "                                column_value=col, default_fc_parameters=selected_features)\n",
    "    extracted_features = pd.concat([extracted_features, features], axis=1)\n",
    "\n",
    "extracted_features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names=extracted_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_features=pd.concat([data_to_extract[['PACJENT_NR', 'ZGON']].groupby(\"PACJENT_NR\").last()[\"ZGON\"], extracted_features], axis=1).rename_axis(\"PACJENT_NR\").reset_index()\n",
    "data_with_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = data_with_features.drop(columns=[\"ZGON\", \"PACJENT_NR\"])\n",
    "y_data = data_with_features[\"ZGON\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, stratify=y_data, test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standaryzacja danych\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(model, X_train, X_test, y_train, y_test, ax, title):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', ax=ax, cmap=\"Reds\", annot_kws={\"fontsize\": 14})\n",
    "    ax.set_title(f'{title}\\ndokładność: {accuracy:.2f}, precyzja: {precision:.2f},\\nczułość: {recall:.2f}, F1-score: {f1:.2f}', fontsize=16)\n",
    "    ax.set_xlabel('Przewidywane', fontsize=14)\n",
    "    ax.set_ylabel('Prawdziwe', fontsize=14)\n",
    "\n",
    "    # Funkcja do trenowania i mierzenia czasu\n",
    "def model_evaluate(classifier, X_train, X_test, y_train, y_test):\n",
    "    y_proba = classifier.predict_proba(X_test)[:, 1]\n",
    "    fpr, tpr, _= roc_curve(y_test, y_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    return fpr, tpr, roc_auc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Klasyfikacja na wszystkich 324 zmiennych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Klasyfikatory\n",
    "\n",
    "classifiers = {\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'LDA': LinearDiscriminantAnalysis(),\n",
    "    'SVC': SVC(),\n",
    "    'DT': DecisionTreeClassifier(),\n",
    "    'RF': RandomForestClassifier()\n",
    "}\n",
    "\n",
    "param_grids = {\n",
    "    'KNN': {'n_neighbors': [5,10,15,20], 'weights': ['uniform', 'distance']},\n",
    "    'LDA': {'solver': ['svd', 'lsqr', 'eigen']},\n",
    "    'SVC': {'C': [0.1, 0.5, 1, 1.5], 'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],  'probability': [True]},\n",
    "    'DT': {'criterion': ['gini', 'entropy'], 'max_depth': [10, 20, 30, 40, 50, None], 'random_state': [seed]},\n",
    "    'RF': {'n_estimators': [5, 10, 50, 100, 200], 'criterion': ['gini', 'entropy'], \n",
    "                      'max_depth': [5, 10, 20, 30, 40, 50,], 'random_state': [seed]}\n",
    "}\n",
    "\n",
    "\n",
    "# Przechowywanie najlepszych modeli i ich wyników\n",
    "best_models_all = {}\n",
    "best_scores_all = {}\n",
    "test_scores_all={}\n",
    "\n",
    "# Przeszukiwanie hiperparametrów dla każdego klasyfikatora\n",
    "for name, classifier in classifiers.items():\n",
    "    print(f\"Przetwarzanie {name}...\")\n",
    "    grid_search = GridSearchCV(classifier, param_grids[name], cv=4, n_jobs=-1, scoring='accuracy',)\n",
    "    grid_search.fit(X_train_scaled, y_train)\n",
    "    best_models_all[name] = (type(grid_search.best_estimator_), grid_search.best_params_)\n",
    "    best_scores_all[name] = grid_search.best_score_\n",
    "    print(f\"Najlepsze parametry dla {name}: {grid_search.best_params_}\")\n",
    "    print(f\"Najlepszy wynik dla {name}: {grid_search.best_score_}\\n\")\n",
    "\n",
    "# Ocena najlepszych modeli na zbiorze testowym\n",
    "for name, (model_type, best_params) in best_models_all.items():\n",
    "    model = model_type(**best_params)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    test_score = accuracy_score(y_test, y_pred)\n",
    "    test_scores_all[name]=test_score\n",
    "    print(f\"Dokładność {name} na zbiorze testowym: {test_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_scores_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "\n",
    "# Lista tytułów\n",
    "titles = ['KNN', 'LDA', 'SVC', 'DT', 'RF']\n",
    "\n",
    "# Rysowanie macierzy pomyłek dla każdego klasyfikatora\n",
    "for ax, (title, (model_type, best_params)) in zip(axes.flatten(), best_models_all.items()):\n",
    "    model = model_type(**best_params)\n",
    "    plot_confusion_matrix(model, X_train_scaled, X_test_scaled, y_train, y_test, ax, title)\n",
    "\n",
    "# Usuwanie niepotrzebnych osi w przypadku parzystej liczby klasyfikatorów\n",
    "if len(classifiers) % 2 != 0:\n",
    "    fig.delaxes(axes.flatten()[-1])\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"images5/conf_matr_all.png\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "for name, (model_type, best_params) in best_models_all.items():\n",
    "    model = model_type(**best_params)\n",
    "    print(model)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    fpr, tpr, roc_auc= model_evaluate(model, X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "    plt.plot(fpr, tpr, lw=2, label=f'{name} (AUC = {roc_auc:.2f})')  # Grubsze linie\n",
    "\n",
    "# Dodanie linii diagonalnej\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "\n",
    "# Ustawienia osi\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "\n",
    "# Powiększenie napisów przy osiach\n",
    "plt.xlabel('Odsetek fałszywie pozytywnych', fontsize=14)\n",
    "plt.ylabel('Odsetek prawdziwie pozytywnych', fontsize=14)\n",
    "\n",
    "# Powiększenie legendy\n",
    "plt.legend(loc='lower right', fontsize=12)\n",
    "\n",
    "plt.savefig(\"images5/roc_all.png\")\n",
    "# Wyświetlenie wykresu\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Klasyfikacja na podstawie najważniejszych skłądowych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA\n",
    "pca = PCA(n_components=0.95)\n",
    "X_pca = pca.fit_transform(X_train_scaled)\n",
    "\n",
    "# Wyjaśniona wariancja\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "\n",
    "# Kumulatywna suma wyjaśnionej wariancji\n",
    "cumulative_explained_variance_ratio = explained_variance_ratio.cumsum()\n",
    "\n",
    "# Tworzenie osypiska (scree plot) za pomocą Plotly\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=list(range(1, len(explained_variance_ratio) + 1)), y=explained_variance_ratio,\n",
    "                         mode='lines+markers', name='Explained Variance Ratio'))\n",
    "# fig.add_trace(go.Scatter(x=list(range(1, len(cumulative_explained_variance_ratio) + 1)), \n",
    "#                          y=cumulative_explained_variance_ratio,\n",
    "#                          mode='lines+markers', name='Cumulative Explained Variance Ratio'))\n",
    "\n",
    "# Dodajemy etykiety i tytuł\n",
    "fig.update_layout(\n",
    "    xaxis=dict(\n",
    "        title='Liczba składowych',\n",
    "        tickfont=dict(size=16),\n",
    "        title_font=dict(size=20),\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Odsetek wariancji',\n",
    "        tickfont=dict(size=16),\n",
    "        title_font=dict(size=20)\n",
    "    )\n",
    ")\n",
    "fig.update_layout(template=\"plotly_white\")\n",
    "\n",
    "\n",
    "# Wyświetlenie wykresu\n",
    "fig.show()\n",
    "fig.write_image(\"images5/osypisko.png\", width=1000, height=600, scale=3, format=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA\n",
    "pca = PCA(n_components=3)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "print(sum(explained_variance_ratio))\n",
    "\n",
    "X_pca_df=pd.DataFrame(X_train_pca, columns=['Czynnik 1', 'Czynnik 2', 'Czynnik 3'])\n",
    "X_pca_df['ZGON'] = y\n",
    "X_pca_df['Czy pacjent zmarł?'] = X_pca_df['ZGON'].map({1: 'tak', 0: 'nie'})\n",
    "\n",
    "fig = px.scatter_3d(X_pca_df, x='Czynnik 1', y='Czynnik 2', z='Czynnik 3', color='Czy pacjent zmarł?', size_max=18, opacity=0.8)\n",
    "fig.update_traces(textposition='top center', marker_size=6)\n",
    "\n",
    "fig.update_layout(\n",
    "    scene=dict(\n",
    "        xaxis=dict(tickfont=dict(size=10)),\n",
    "        yaxis=dict(tickfont=dict(size=10)),\n",
    "        zaxis=dict(tickfont=dict(size=10)),\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(legend=dict(font=dict(size=14)), legend_title=dict(font=dict(size=14)))\n",
    "fig.update_layout(template=\"plotly_white\")\n",
    "fig.show()\n",
    "\n",
    "# fig.write_image(\"images5/\" + \"pca_miernik_3d\" + \".png\", width=1000, height=600, scale=3, format=\"png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=7) #22\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "print(sum(explained_variance_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Klasyfikatory\n",
    "\n",
    "classifiers = {\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'LDA': LinearDiscriminantAnalysis(),\n",
    "    'SVC': SVC(),\n",
    "    'DT': DecisionTreeClassifier(),\n",
    "    'RF': RandomForestClassifier()\n",
    "}\n",
    "\n",
    "\n",
    "param_grids = {\n",
    "    'KNN': {'n_neighbors': [5,10,15,20], 'weights': ['uniform', 'distance']},\n",
    "    'LDA': {'solver': ['svd', 'lsqr', 'eigen']},\n",
    "    'SVC': {'C': [0.1, 0.5, 1, 1.5], 'kernel': ['linear', 'rbf', 'poly', 'sigmoid'], 'gamma': [0.001, 0.01, 0.1, 1],  'probability': [True]},\n",
    "    'DT': {'criterion': ['gini', 'entropy'], 'max_depth': [10, 20, 30, 40, 50, None], 'random_state': [seed]},\n",
    "    'RF': {'n_estimators': [5, 10, 50, 100, 200], 'criterion': ['gini', 'entropy'], \n",
    "                      'max_depth': [5, 10, 20, 30, 40, 50,], 'random_state': [seed]}\n",
    "}\n",
    "\n",
    "\n",
    "# Przechowywanie najlepszych modeli i ich wyników\n",
    "best_models_pca = {}\n",
    "best_scores_pca = {}\n",
    "test_scores_pca= {}\n",
    "\n",
    "# Przeszukiwanie hiperparametrów dla każdego klasyfikatora\n",
    "for name, classifier in classifiers.items():\n",
    "    print(f\"Przetwarzanie {name}...\")\n",
    "    grid_search = GridSearchCV(classifier, param_grids[name], cv=4, n_jobs=-1, scoring='accuracy',)\n",
    "    grid_search.fit(X_train_pca, y_train)\n",
    "    best_models_pca[name] = (type(grid_search.best_estimator_), grid_search.best_params_)\n",
    "    best_scores_pca[name] = grid_search.best_score_\n",
    "    print(f\"Najlepsze parametry dla {name}: {grid_search.best_params_}\")\n",
    "    print(f\"Najlepszy wynik dla {name}: {grid_search.best_score_}\\n\")\n",
    "\n",
    "# Ocena najlepszych modeli na zbiorze testowym\n",
    "for name, (model_type, best_params) in best_models_pca.items():\n",
    "    model = model_type(**best_params)\n",
    "    model.fit(X_train_pca, y_train)\n",
    "    y_pred = model.predict(X_test_pca)\n",
    "    test_score = accuracy_score(y_test, y_pred)\n",
    "    test_scores_pca[name]=test_score\n",
    "    print(f\"Dokładność {name} na zbiorze testowym: {test_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_scores_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Krzywe ROC\n",
    "plt.figure(figsize=(8, 6))\n",
    "for name, (model_type, best_params) in best_models_pca.items():\n",
    "    model = model_type(**best_params)\n",
    "    model.fit(X_train_pca, y_train)\n",
    "    y_pred = model.predict(X_test_pca)\n",
    "    fpr, tpr, roc_auc= model_evaluate(model, X_train_pca, X_test_pca, y_train, y_test)\n",
    "    plt.plot(fpr, tpr, lw=2, label=f'{name} (AUC = {roc_auc:.2f})')  # Grubsze linie\n",
    "\n",
    "# Dodanie linii diagonalnej\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "\n",
    "# Ustawienia osi\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "\n",
    "# Powiększenie napisów przy osiach\n",
    "plt.xlabel('Odsetek fałszywie pozytywnych', fontsize=14)\n",
    "plt.ylabel('Odsetek prawdziwie pozytywnych', fontsize=14)\n",
    "\n",
    "# Powiększenie legendy\n",
    "plt.legend(loc='lower right', fontsize=12)\n",
    "\n",
    "plt.savefig(\"images5/roc_pca.png\")\n",
    "# Wyświetlenie wykresu\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "\n",
    "# Lista tytułów\n",
    "titles = ['KNN', 'LDA', 'SVC', 'DT', 'RF']\n",
    "\n",
    "# Rysowanie macierzy pomyłek dla każdego klasyfikatora\n",
    "for ax, (title, (model_type, best_params)) in zip(axes.flatten(), best_models_all.items()):\n",
    "    model = model_type(**best_params)\n",
    "    plot_confusion_matrix(model, X_train_pca, X_test_pca, y_train, y_test, ax, title)\n",
    "\n",
    "# Usuwanie niepotrzebnych osi w przypadku parzystej liczby klasyfikatorów\n",
    "if len(classifiers) % 2 != 0:\n",
    "    fig.delaxes(axes.flatten()[-1])\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"images5/conf_matr_pca.png\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wyszukiwanie liczby cech ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ustawienie różnych wartości C dla SVC\n",
    "C_values = [0.05, 0.1, 0.5, 1, 1.2]\n",
    "\n",
    "# Przechowywanie wyników\n",
    "results = []\n",
    "\n",
    "# Iterowanie przez różne wartości C\n",
    "for C in C_values:\n",
    "    svc_linear = SVC(kernel='linear', C=C, random_state=42)\n",
    "    \n",
    "    # Definiowanie RFECV z SVC (liniowym) jako estymatora\n",
    "    rfecv = RFECV(estimator=svc_linear, step=1, cv=4, scoring='accuracy')\n",
    "    rfecv.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    n_features=rfecv.n_features_\n",
    "\n",
    "    # Transformowanie danych na podstawie wybranych cech\n",
    "    X_train_rfecv = rfecv.transform(X_train_scaled)\n",
    "    X_test_rfecv = rfecv.transform(X_test_scaled)\n",
    "    \n",
    "    classifiers = {\n",
    "        'KNN': KNeighborsClassifier(),\n",
    "        'LDA': LinearDiscriminantAnalysis(),\n",
    "        'SVC': SVC(),\n",
    "        'DT': DecisionTreeClassifier(),\n",
    "        'RF': RandomForestClassifier()\n",
    "    }\n",
    "\n",
    "    param_grids = {\n",
    "        'KNN': {'n_neighbors': [5,10,15,20], 'weights': ['uniform', 'distance']},\n",
    "        'LDA': {'solver': ['svd', 'lsqr', 'eigen']},\n",
    "        'SVC': {'C': [0.1, 0.5, 1, 1.5], 'kernel': ['linear', 'rbf', 'poly', 'sigmoid'], 'probability': [True]},\n",
    "        'DT': {'criterion': ['gini', 'entropy'], 'max_depth': [10, 20, 30, 40, 50], 'random_state': [42]},\n",
    "        'RF': {'n_estimators': [5, 10, 50, 100, 200], 'criterion': ['gini', 'entropy'], \n",
    "                          'max_depth': [5, 10, 20, 30, 40, 50], 'random_state': [42]}\n",
    "    }\n",
    "\n",
    "    # Przeszukiwanie hiperparametrów dla każdego klasyfikatora\n",
    "    for name, classifier in classifiers.items():\n",
    "        grid_search = GridSearchCV(classifier, param_grids[name], cv=4, n_jobs=-1, scoring='accuracy')\n",
    "        grid_search.fit(X_train_rfecv, y_train)\n",
    "        results.append({'Model': name, 'C': C, 'Best Score': grid_search.best_score_, 'n_features': n_features})\n",
    "    \n",
    "# Konwertowanie wyników do ramki danych\n",
    "results_df = pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rysowanie wykresu kolumnowego\n",
    "results_df['C_n_features'] = results_df['C'].astype(str) + ' (liczba cech=' + results_df['n_features'].astype(str) + ')'\n",
    "palette = sns.color_palette([\"#2ecc71\", \"#3498db\", \"#e74c3c\", \"#9b59b6\", \"#f1c40f\"])\n",
    "\n",
    "results_df['C'] = results_df['C'].astype(str).str.replace('.', ',')\n",
    "results_df['C_n_features'] = results_df['C'] + ' (liczba cech=' + results_df['n_features'].astype(str) + ')'\n",
    "\n",
    "\n",
    "# Rysowanie wykresu kolumnowego\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "sns.barplot(data=results_df, x='C_n_features', y='Best Score', hue='Model', palette=palette)\n",
    "plt.xlabel('\\nKoszt C (wraz z liczbą wybranych cech)', fontsize=14)\n",
    "plt.ylabel('Dokładność', fontsize=14)\n",
    "plt.ylim([0,1])\n",
    "plt.legend(title='Model', bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=14,  title_fontsize=16)\n",
    "plt.tick_params(axis='both', which='major', labelsize=12)\n",
    "\n",
    "plt.savefig(\"images5/comparision_cost.png\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Klasyfikacja na podstawie najważniejszych zmiennych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Użycie SVC z liniowym jądrem dla RFECV\n",
    "svc_linear = SVC(kernel='linear', C=0.05)\n",
    "\n",
    "# Definiowanie RFECV z SVC (liniowym) jako estymatora\n",
    "rfecv = RFECV(estimator=svc_linear, step=1, cv=4, scoring='accuracy')\n",
    "rfecv.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Transformowanie danych na podstawie wybranych cech\n",
    "X_train_rfecv = rfecv.transform(X_train_scaled)\n",
    "X_test_rfecv = rfecv.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfecv.n_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "min_features_to_select = 1\n",
    "n_scores = len(rfecv.cv_results_[\"mean_test_score\"])\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=list(range(min_features_to_select, n_scores + min_features_to_select)),\n",
    "    y=rfecv.cv_results_[\"mean_test_score\"],\n",
    "    mode='lines'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Liczba zmiennych\",\n",
    "    yaxis_title=\"Dokładność\",\n",
    "    yaxis=dict(range=[0.5, 0.9]),\n",
    "    xaxis=dict(range=[0, 100])\n",
    ")\n",
    "\n",
    "fig.update_layout(template=\"plotly_white\")\n",
    "\n",
    "fig.write_image(\"images5/zmienne_rfecv.png\", width=1000, height=600, scale=4, format=\"png\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'LDA': LinearDiscriminantAnalysis(),\n",
    "    'SVC': SVC(),\n",
    "    'DT': DecisionTreeClassifier(),\n",
    "    'RF': RandomForestClassifier()\n",
    "}\n",
    "\n",
    "param_grids = {\n",
    "    'KNN': {'n_neighbors': [5,10,15,20], 'weights': ['uniform', 'distance']},\n",
    "    'LDA': {'solver': ['svd', 'lsqr', 'eigen']},\n",
    "    'SVC': {'C': [0.1, 0.5, 1, 1.5], 'kernel': ['linear', 'rbf', 'poly', 'sigmoid'], 'probability': [True]},\n",
    "    'DT': {'criterion': ['gini', 'entropy'], 'max_depth': [10, 20, 30, 40, 50], 'random_state': [seed]},\n",
    "    'RF': {'n_estimators': [5, 10, 50, 100, 200], 'criterion': ['gini', 'entropy'], \n",
    "                      'max_depth': [5, 10, 20, 30, 40, 50], 'random_state': [seed]}\n",
    "}\n",
    "\n",
    "\n",
    "# Przechowywanie najlepszych modeli i ich wyników\n",
    "best_models_rfe = {}\n",
    "best_scores_rfe = {}\n",
    "test_scores_rfe = {}\n",
    "best_models_rfe_class={}\n",
    "\n",
    "# Przeszukiwanie hiperparametrów dla każdego klasyfikatora\n",
    "for name, classifier in classifiers.items():\n",
    "    print(f\"Przetwarzanie {name}...\")\n",
    "    grid_search = GridSearchCV(classifier, param_grids[name], cv=4, n_jobs=-1, scoring='accuracy')\n",
    "    grid_search.fit(X_train_rfecv, y_train)\n",
    "    best_models_rfe_class[name]=grid_search.best_estimator_\n",
    "    best_models_rfe[name] = (type(grid_search.best_estimator_), grid_search.best_params_)\n",
    "    best_scores_rfe[name] = grid_search.best_score_\n",
    "    print(f\"Najlepsze parametry dla {name}: {grid_search.best_params_}\")\n",
    "    print(f\"Najlepszy wynik dla {name}: {grid_search.best_score_}\\n\")\n",
    "\n",
    "# Ocena najlepszych modeli na zbiorze testowym\n",
    "for name, (model_type, best_params) in best_models_rfe.items():\n",
    "    model = model_type(**best_params)\n",
    "    model.fit(X_train_rfecv, y_train)\n",
    "    y_pred = model.predict(X_test_rfecv)\n",
    "    test_score = accuracy_score(y_test, y_pred)\n",
    "    test_scores_rfe[name]=test_score\n",
    "    print(f\"Dokładność {name} na zbiorze testowym: {test_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_scores_rfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores_rfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'Model': best_scores_all.keys(),\n",
    "    'Best Score all': best_scores_all.values(),\n",
    "    'Test Score all': test_scores_all.values(),\n",
    "    'Best Score pca': best_scores_pca.values(),\n",
    "    'Test Score pca': test_scores_pca.values(),\n",
    "    'Best Score rfe': best_scores_rfe.values(),\n",
    "    'Test Score rfe': test_scores_rfe.values(),\n",
    "})\n",
    "\n",
    "# Przekształcenie ramki danych do formatu długiego\n",
    "df_melted = df.melt(id_vars='Model', var_name='Score Type', value_name='Score')\n",
    "\n",
    "# Tworzenie wykresu kolumnowego\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.barplot(x='Score Type', y='Score', hue='Model', data=df_melted)\n",
    "\n",
    "# Dostosowanie wyglądu wykresu\n",
    "plt.title('Porównanie wyników różnych modeli')\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Score Type')\n",
    "plt.ylim(0, 1)\n",
    "plt.legend(title='Model', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models_rfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "\n",
    "# Lista tytułów\n",
    "titles = ['KNN', 'LDA', 'SVC', 'DT', 'RF']\n",
    "\n",
    "# Rysowanie macierzy pomyłek dla każdego klasyfikatora\n",
    "for ax, (title, (model_type, best_params)) in zip(axes.flatten(), best_models_rfe.items()):\n",
    "    model = model_type(**best_params)\n",
    "    plot_confusion_matrix(model, X_train_rfecv, X_test_rfecv, y_train, y_test, ax, title)\n",
    "\n",
    "# Usuwanie niepotrzebnych osi w przypadku parzystej liczby klasyfikatorów\n",
    "if len(classifiers) % 2 != 0:\n",
    "    fig.delaxes(axes.flatten()[-1])\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"images5/conf_matr_rfe.png\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(model_type, best_params)=best_models_rfe[\"SVC\"]\n",
    "model = model_type(**best_params)\n",
    "model.fit(X_train_rfecv,  y_train)\n",
    "\n",
    "# Uzyskanie współczynników cech\n",
    "coefs = model.coef_[0]\n",
    "\n",
    "# Stworzenie wykresu współczynników cech\n",
    "feature_names = [\"Cecha 1\", \"Cecha 2\", \"Cecha 3\", \"Cecha 4\", \"Cecha 5\", \"Cecha 6\"] #\n",
    "\n",
    "# Posortowanie cech według ich współczynników\n",
    "sorted_idx = np.argsort(coefs)\n",
    "sorted_coefs = coefs[sorted_idx]\n",
    "sorted_features = feature_names #feature_names[sorted_idx]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(sorted_features, sorted_coefs, color='#0097ca')\n",
    "plt.xlabel(\"Współczynniki cech w modelu\", fontsize=16)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "# plt.title(\"Istotność cech w modelu SVC z liniową funkcją jądra\")\n",
    "plt.savefig(\"images5/waznosc_cech.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test_rfecv)\n",
    "por=y_test.reset_index()\n",
    "por[\"y_pred\"]=y_pred\n",
    "por.iloc[np.where(por[\"ZGON\"]!=por[\"y_pred\"])][\"index\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df = pd.DataFrame(X_train_rfecv).reset_index(drop=True)\n",
    "# columns=feature_names\n",
    "# Przekształcenie y_train do DataFrame i nadanie kolumnie nazwy \"ZGON\"\n",
    "y_train_df = pd.DataFrame(y_train, columns=[\"ZGON\"]).reset_index(drop=True)\n",
    "\n",
    "# Połączenie X_train_df i y_train_df wzdłuż osi kolumn (axis=1)\n",
    "data_6_vars = pd.concat([X_train_df, y_train_df], axis=1)\n",
    "\n",
    "# Wyświetlenie wynikowej ramki danych\n",
    "data_6_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names_skr=['BETET_piki', 'BETET_loc_min',\n",
    "       'HCO3STTE_loc_max', 'IONH_piki',\n",
    "       'IONH_loc_max',\n",
    "       'mean_slope_miernik2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wyświetlenie wynikowej ramki danych\n",
    "data_6_vars=data_with_features[[*names[rfecv.support_], \"ZGON\", \"PACJENT_NR\"]]\n",
    "# data_6_vars.columns=[0,1,2,3,4,5,\"ZGON\"]\n",
    "data_6_vars.columns=[*feature_names, \"ZGON\", \"PACJENT_NR\"]\n",
    "data_6_vars.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_features.iloc[59][\"PACJENT_NR\"]\n",
    "data_with_features.iloc[13][\"PACJENT_NR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=[\"Cecha 1\", \"Cecha 2\", \"Cecha 3\", \"Cecha 4\", \"Cecha 5\", \"Cecha 6\"]\n",
    "my_blue=\"#0064B2\"\n",
    "my_red=\"#D61600\"\n",
    "fig = go.Figure()\n",
    "\n",
    "# Użycie pd.melt() do przekształcenia ramki danych do długiego formatu\n",
    "melted_data = pd.melt(data_6_vars, id_vars=[\"ZGON\", \"PACJENT_NR\"], value_vars=cols,\n",
    "                      var_name=\"Cecha\", value_name=\"Wartość\")\n",
    "\n",
    "# Tworzenie wykresu boxplot za pomocą Plotly Express\n",
    "fig = px.box(melted_data, x=\"Cecha\", y=\"Wartość\", color=\"ZGON\",\n",
    "             labels={\"Cecha\": \"Cecha\", \"Wartość\": \"Wartość\", \"ZGON\": \"Klasa ZGON\"}, points='all')\n",
    "\n",
    "# Ustawienie customdata\n",
    "fig.update_traces(customdata=melted_data[\"PACJENT_NR\"])\n",
    "\n",
    "# Dodanie numeru pacjenta do etykiet punktów\n",
    "fig.update_traces(\n",
    "    hovertemplate='%{x}: %{y} <br> Pacjent: %{customdata}'\n",
    ")\n",
    "\n",
    "# Dostosowanie rozmiaru czcionki osi x i y\n",
    "fig.update_layout(xaxis=dict(tickfont=dict(size=18), title=\"\"), yaxis=dict(tickfont=dict(size=16),  title=dict(font=dict(size=18))))\n",
    "fig.update_layout(showlegend=False)\n",
    "fig.update_layout(height=600, width=1200)\n",
    "fig.update_layout(template=\"plotly_white\")\n",
    "fig.show()\n",
    "fig.write_image(\"images5/rozklad_najw_cech.png\", format=\"png\", scale=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_features.iloc[59, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names[rfecv.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Krzywe ROC\n",
    "plt.figure(figsize=(8, 6))\n",
    "for name, (model_type, best_params) in best_models_rfe.items():\n",
    "    model = model_type(**best_params)\n",
    "    model.fit(X_train_rfecv, y_train)\n",
    "    y_pred = model.predict(X_test_rfecv)\n",
    "    fpr, tpr, roc_auc= model_evaluate(model, X_train_rfecv, X_test_rfecv, y_train, y_test)\n",
    "    plt.plot(fpr, tpr, lw=2, label=f'{name} (AUC = {roc_auc:.2f})')  # Grubsze linie\n",
    "\n",
    "# Dodanie linii diagonalnej\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "\n",
    "# Ustawienia osi\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "\n",
    "# Powiększenie napisów przy osiach\n",
    "plt.xlabel('Odsetek fałszywie pozytywnych', fontsize=14)\n",
    "plt.ylabel('Odsetek prawdziwie pozytywnych', fontsize=14)\n",
    "\n",
    "# Powiększenie legendy\n",
    "plt.legend(loc='lower right', fontsize=12)\n",
    "\n",
    "plt.savefig(\"images5/roc_rfe.png\")\n",
    "# Wyświetlenie wykresu\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Klasyfikacja w czasie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_vars=['BETET_kw', 'HCO3STTE_kw', 'IONH_kw', 'euclidean_kw']\n",
    "\n",
    "data_to_extract2=data_to_extract[['PACJENT_NR', 'BADANIE_NR', *chosen_vars]]\n",
    "\n",
    "selected_features_dict = {\n",
    "    'BETET_kw': {\n",
    "        'number_peaks': [{'n': 2}],\n",
    "        'first_location_of_minimum': None\n",
    "    },\n",
    "    'IONH_kw': {\n",
    "        'number_peaks': [{'n': 2}],\n",
    "        'first_location_of_maximum': None\n",
    "    },\n",
    "    'HCO3STTE_kw': {\n",
    "        'first_location_of_maximum': None\n",
    "    },\n",
    "    'euclidean_kw': {\n",
    "        'agg_linear_trend': [{'f_agg': 'mean', 'chunk_len': 6, 'attr': 'slope'}]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results2 = []\n",
    "\n",
    "for n_badan in range(1, 65):\n",
    "    # Filtrowanie danych do n_badan\n",
    "    data_subset = data_to_extract2[data_to_extract2['BADANIE_NR'] <= n_badan]\n",
    "\n",
    "    extracted_features_6 = pd.DataFrame()\n",
    "\n",
    "    # Iteracja po wybranych zmiennych\n",
    "    for col in chosen_vars:\n",
    "        selected_features = selected_features_dict.get(col, {})\n",
    "        features = extract_features(data_subset, column_id=\"PACJENT_NR\", column_sort=\"BADANIE_NR\", \n",
    "                                    column_value=col, default_fc_parameters=selected_features)\n",
    "        features.columns = [f\"{col}_{feature}\" for feature in features.columns]\n",
    "        extracted_features_6 = pd.concat([extracted_features_6, features], axis=1)\n",
    "\n",
    "    # Przygotowanie danych do modelowania\n",
    "    X = extracted_features_6.dropna(axis=1, how='all')\n",
    "\n",
    "    # Podział danych na zbiory treningowy i testowy\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed, stratify=y)\n",
    "    \n",
    "    # Standaryzacja danych\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    classifiers = {\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'LDA': LinearDiscriminantAnalysis(),\n",
    "    'SVC': SVC(),\n",
    "    'DT': DecisionTreeClassifier(),\n",
    "    'RF': RandomForestClassifier()\n",
    "    }\n",
    "\n",
    "    param_grids = {\n",
    "    'KNN': {'n_neighbors': [5,10,15,20], 'weights': ['uniform', 'distance']},\n",
    "    'LDA': {'solver': ['svd', 'lsqr', 'eigen']},\n",
    "    'SVC': {'C': [0.1, 0.5, 1, 1.5], 'kernel': ['linear', 'rbf', 'poly', 'sigmoid'], 'probability': [True]},\n",
    "    'DT': {'criterion': ['gini', 'entropy'], 'max_depth': [10, 20, 30, 40, 50], 'random_state': [seed]},\n",
    "    'RF': {'n_estimators': [5, 10, 50, 100, 200], 'criterion': ['gini', 'entropy'], \n",
    "                      'max_depth': [5, 10, 20, 30, 40, 50], 'random_state': [seed]}\n",
    "    }\n",
    "\n",
    "    best_models_for_n={}\n",
    "    test_scores_for_n={}\n",
    "\n",
    "    # Przeszukiwanie hiperparametrów dla każdego klasyfikatora\n",
    "    for name, classifier in classifiers.items():\n",
    "        grid_search = GridSearchCV(classifier, param_grids[name], cv=4, n_jobs=-1, scoring='accuracy')\n",
    "        grid_search.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        model_type=type(classifier)\n",
    "        best_params=grid_search.best_params_\n",
    "\n",
    "        test_scores=[]\n",
    "        recalls=[]\n",
    "        precisions=[]\n",
    "        f1_scores=[]\n",
    "        \n",
    "        for i in range(100):\n",
    "            X_btrain, X_btest, y_btrain, y_btest = train_test_split(X, y, test_size=0.2, random_state=i, stratify=y)\n",
    "\n",
    "            scaler2 = StandardScaler()\n",
    "            X_btrain_scaled = scaler2.fit_transform(X_btrain)\n",
    "            X_btest_scaled = scaler2.transform(X_btest)\n",
    "\n",
    "            best_model=model_type(**best_params)\n",
    "            best_model.fit(X_btrain_scaled, y_btrain)\n",
    "            y_bpred = best_model.predict(X_btest_scaled)\n",
    "            test_scores.append(accuracy_score(y_btest, y_bpred))\n",
    "            precisions.append(precision_score(y_btest, y_bpred))\n",
    "            recalls.append(recall_score(y_btest, y_bpred))\n",
    "            f1_scores.append(f1_score(y_btest, y_bpred))\n",
    "        \n",
    "        mean_test_score=np.mean(test_scores)\n",
    "        mean_recall=np.mean(recalls)\n",
    "        mean_precision=np.mean(precisions)\n",
    "        mean_f1_score=np.mean(f1_scores)\n",
    "\n",
    "        best_model=model_type(**best_params)\n",
    "        best_model.fit(X_train_scaled, y_train)\n",
    "        y_pred = best_model.predict(X_test_scaled)\n",
    "        test_acc=accuracy_score(y_test, y_pred)\n",
    "        test_prec=precision_score(y_test, y_pred)\n",
    "        test_recall=recall_score(y_test, y_pred)\n",
    "        test_f1=f1_score(y_test, y_pred)\n",
    "    \n",
    "        results2.append({'n_badan': n_badan, 'Model': name, 'parameters': best_params, 'Dokładność test': test_acc, 'Czułość test': test_recall, \n",
    "                         'Precyzja test': test_prec, 'F1-score test': test_f1, 'Dokładność 100 test': mean_test_score, 'Czułość 100 test': mean_recall, \n",
    "                         'Precyzja 100 test': mean_precision, 'F1-score 100 test': mean_f1_score})\n",
    "\n",
    "    # # Ocena najlepszych modeli na zbiorze testowym\n",
    "    # for name, (model_type, best_params) in best_models_for_n.items():\n",
    "    #     model = model_type(**best_params)\n",
    "    #     model.fit(X_train_scaled, y_train)\n",
    "    #     y_pred = model.predict(X_test_scaled)\n",
    "    #     test_score = accuracy_score(y_test, y_pred)\n",
    "    #     results2.append({'n_badan': n_badan, 'Model': name, 'Dokładność': test_score, 'parameters': best_models_for_n[name]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df=pd.DataFrame(results2)\n",
    "results_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=results_df[['n_badan', 'Model', 'Dokładność 100 test', 'Precyzja 100 test', 'Czułość 100 test', 'F1-score 100 test']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_label='Numer badania'\n",
    "title='klasyfikacja_obserwacje_accuracy'\n",
    "# results_df = results_df[results_df['Model'].isin(['LDA', 'KNN'])]\n",
    "fig = px.line(results_df, x='n_badan', y='F1-score 100 test', color='Model', markers=True, line_shape='linear')\n",
    "\n",
    "# Dodajemy etykiety i tytuł\n",
    "fig.update_layout(\n",
    "    xaxis=dict(\n",
    "        title=x_label,\n",
    "        tickfont=dict(size=16),\n",
    "        title_font=dict(size=20),\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='F1-score',\n",
    "        tickfont=dict(size=16),\n",
    "        title_font=dict(size=20),\n",
    "        range=[0, 1]\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(template=\"plotly_white\")\n",
    "fig.show()\n",
    "# fig.write_image(\"images5/wykresy_w_czasie_lda_knn.png\", width=1000, height=600, scale=4, format=\"png\")\n",
    "fig.write_image(\"images5/wykresy_w_czasie_100_fscore.png\", width=1000, height=600, scale=4, format=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df2=results_df[results_df['n_badan']>=1]\n",
    "\n",
    "x_label='Numer badania'\n",
    "title='klasyfikacja_obserwacje_accuracy'\n",
    "# results_df = results_df[results_df['Model'].isin(['LDA', 'KNN'])]\n",
    "fig = px.line(results_df, x='n_badan', y='Dokładność 100 test', color='Model', markers=True, line_shape='linear')\n",
    "\n",
    "# Dodajemy etykiety i tytuł\n",
    "fig.update_layout(\n",
    "    xaxis=dict(\n",
    "        title=x_label,\n",
    "        tickfont=dict(size=16),\n",
    "        title_font=dict(size=20),\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Dokładność',\n",
    "        tickfont=dict(size=16),\n",
    "        title_font=dict(size=20),\n",
    "        range=[0, 1]\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(template=\"plotly_white\")\n",
    "fig.show()\n",
    "fig.write_image(\"images5/wykresy_w_czasie_100_dokladnosc_test.png\", width=1000, height=600, scale=4, format=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_badan=6\n",
    "# Filtrowanie danych do n_badan\n",
    "data_subset = data_to_extract2[data_to_extract2['BADANIE_NR'] <= n_badan]\n",
    "\n",
    "extracted_features_6 = pd.DataFrame()\n",
    "\n",
    "# Iteracja po wybranych zmiennych\n",
    "for col in chosen_vars:\n",
    "    selected_features = selected_features_dict.get(col, {})\n",
    "    features = extract_features(data_subset, column_id=\"PACJENT_NR\", column_sort=\"BADANIE_NR\", \n",
    "                                column_value=col, default_fc_parameters=selected_features)\n",
    "    features.columns = [f\"{col}_{feature}\" for feature in features.columns]\n",
    "    extracted_features_6 = pd.concat([extracted_features_6, features], axis=1)\n",
    "\n",
    "# Przygotowanie danych do modelowania\n",
    "X6 = extracted_features_6.dropna(axis=1, how='all')\n",
    "\n",
    "# Podział danych na zbiory treningowy i testowy\n",
    "X_train6, X_test6, y_train, y_test = train_test_split(X6, y, test_size=0.2, random_state=seed, stratify=y)\n",
    "\n",
    "# Standaryzacja danych\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled6 = scaler.fit_transform(X_train6)\n",
    "X_test_scaled6 = scaler.transform(X_test6)\n",
    "\n",
    "classifiers = {\n",
    "'KNN': KNeighborsClassifier(),\n",
    "'LDA': LinearDiscriminantAnalysis(),\n",
    "'SVC': SVC(),\n",
    "'DT': DecisionTreeClassifier(),\n",
    "'RF': RandomForestClassifier()\n",
    "}\n",
    "\n",
    "param_grids = {\n",
    "'KNN': {'n_neighbors': [5,10,15,20], 'weights': ['uniform', 'distance']},\n",
    "'LDA': {'solver': ['svd', 'lsqr', 'eigen']},\n",
    "'SVC': {'C': [0.1, 0.5, 1, 1.5], 'kernel': ['linear', 'rbf', 'poly', 'sigmoid'], 'probability': [True]},\n",
    "'DT': {'criterion': ['gini', 'entropy'], 'max_depth': [10, 20, 30, 40, 50], 'random_state': [seed]},\n",
    "'RF': {'n_estimators': [5, 10, 50, 100, 200], 'criterion': ['gini', 'entropy'], \n",
    "                    'max_depth': [5, 10, 20, 30, 40, 50], 'random_state': [seed]}\n",
    "}\n",
    "\n",
    "# Przechowywanie najlepszych modeli i ich wyników\n",
    "best_models6 = {}\n",
    "best_scores6 = {}\n",
    "test_scores6 = {}\n",
    "best_models_class6={}\n",
    "\n",
    "# Przeszukiwanie hiperparametrów dla każdego klasyfikatora\n",
    "for name, classifier in classifiers.items():\n",
    "    print(f\"Przetwarzanie {name}...\")\n",
    "    grid_search = GridSearchCV(classifier, param_grids[name], cv=4, n_jobs=-1, scoring='accuracy')\n",
    "    grid_search.fit(X_train6, y_train)\n",
    "    best_models_class6[name]=grid_search.best_estimator_\n",
    "    best_models6[name] = (type(grid_search.best_estimator_), grid_search.best_params_)\n",
    "    best_scores6[name] = grid_search.best_score_\n",
    "    print(f\"Najlepsze parametry dla {name}: {grid_search.best_params_}\")\n",
    "    print(f\"Najlepszy wynik dla {name}: {grid_search.best_score_}\\n\")\n",
    "\n",
    "# Ocena najlepszych modeli na zbiorze testowym\n",
    "for name, (model_type, best_params) in best_models6.items():\n",
    "    model = model_type(**best_params)\n",
    "    model.fit(X_train6, y_train)\n",
    "    y_pred = model.predict(X_test6)\n",
    "    test_score = accuracy_score(y_test, y_pred)\n",
    "    test_scores6[name]=test_score\n",
    "    print(f\"Dokładność {name} na zbiorze testowym: {test_score}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "\n",
    "# Lista tytułów\n",
    "titles = ['KNN', 'LDA', 'SVC', 'DT', 'RF']\n",
    "\n",
    "# Rysowanie macierzy pomyłek dla każdego klasyfikatora\n",
    "for ax, (title, (model_type, best_params)) in zip(axes.flatten(), best_models6.items()):\n",
    "    model = model_type(**best_params)\n",
    "    plot_confusion_matrix(model, X_train6, X_test6, y_train, y_test, ax, title)\n",
    "\n",
    "# Usuwanie niepotrzebnych osi w przypadku parzystej liczby klasyfikatorów\n",
    "if len(classifiers) % 2 != 0:\n",
    "    fig.delaxes(axes.flatten()[-1])\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"images5/conf_matr_6.png\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
